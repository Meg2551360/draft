{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7a0325",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d349f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import zipfile\n",
    "# import os\n",
    "\n",
    "# # 2. Распаковка в папку pdf_files\n",
    "# zip_filename = \"pdf_files.zip\"\n",
    "# extract_folder = \"pdf_files\"\n",
    "\n",
    "# # Создаём папку, если её нет\n",
    "# os.makedirs(extract_folder, exist_ok=True)\n",
    "\n",
    "# # Распаковываем\n",
    "# with zipfile.ZipFile(zip_filename, 'r') as zip_ref:\n",
    "#     zip_ref.extractall(extract_folder)\n",
    "\n",
    "# print(f\"Архив {zip_filename} распакован в папку {extract_folder}/\")\n",
    "\n",
    "!unzip -q pdf_files.zip -d /content  # Распаковываем в корень\n",
    "!mv /content/pdf_files /content/my_pdfs  # Переименовываем (опционально)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad096a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import fitz  # PyMuPDF\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "from torchvision.datasets import ImageFolder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6db291d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import fitz\n",
    "from PIL import Image, UnidentifiedImageError\n",
    "import pandas as pd\n",
    "\n",
    "def extract_images_from_pdf(pdf_path, output_folder):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    base_name = os.path.splitext(os.path.basename(pdf_path))[0]\n",
    "    metadata_list = []\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    # Получаем оглавление (TOC) для определения глав\n",
    "    toc = doc.get_toc()\n",
    "\n",
    "    # Улучшенное регулярное выражение для подписей\n",
    "    caption_pattern = re.compile(\n",
    "        r'^(?:(?:Fig(?:ure)?|Рис(?:унок)?)\\s*[\\d\\.]+[\\-–:]?|'  # Английские и русские варианты\n",
    "        r'^\\d+[\\.\\-–]?\\s*|'                                   # Нумерация в начале строки\n",
    "        r'^[A-Za-zА-Яа-я]+\\s*\\d+[\\.\\-–:]?)'                   # Текстовые префиксы\n",
    "        r'\\s*(.*)', \n",
    "        re.IGNORECASE | re.MULTILINE\n",
    "    )\n",
    "\n",
    "    for page_num in range(len(doc)):\n",
    "        page = doc[page_num]\n",
    "        images = page.get_images(full=True)\n",
    "        text_blocks = page.get_text(\"blocks\")\n",
    "\n",
    "        # Определяем главу для текущей страницы\n",
    "        chapter = None\n",
    "        for level, title, p in toc:\n",
    "            if p <= page_num + 1:\n",
    "                chapter = title\n",
    "            else:\n",
    "                break\n",
    "\n",
    "        for img_idx, img in enumerate(images):\n",
    "            xref = img[0]\n",
    "            try:\n",
    "                base_image = doc.extract_image(xref)\n",
    "                img_data = base_image[\"image\"]\n",
    "                img_ext = base_image[\"ext\"]\n",
    "                img_name = f\"{base_name}_p{page_num+1}_i{img_idx+1}.{img_ext}\"\n",
    "                img_path = os.path.join(output_folder, img_name)\n",
    "                \n",
    "                with open(img_path, \"wb\") as f:\n",
    "                    f.write(img_data)\n",
    "\n",
    "                pil_img = Image.open(img_path)\n",
    "                width, height = pil_img.size\n",
    "                is_color = 1 if pil_img.mode in ['RGB', 'RGBA'] else 0\n",
    "\n",
    "                # Определение класса (agr/ds)\n",
    "                file_class = 'agr' if 'agr' in base_name.lower() else 'ds' if 'ds' in base_name.lower() else None\n",
    "\n",
    "                # Поиск подписи в радиусе 100 пунктов вокруг изображения\n",
    "                caption = None\n",
    "                try:\n",
    "                    img_rect = page.get_image_bbox(xref)\n",
    "                    search_rect = img_rect + (-50, -50, 50, 100)  # Расширенная область поиска\n",
    "                    \n",
    "                    # Собираем весь текст вокруг изображения\n",
    "                    context_text = page.get_text(\"text\", clip=search_rect)\n",
    "                    \n",
    "                    # Ищем подпись в собранном тексте\n",
    "                    for line in context_text.split('\\n'):\n",
    "                        line = line.strip()\n",
    "                        if match := caption_pattern.match(line):\n",
    "                            caption = match.group(1).strip()\n",
    "                            if not caption:  # Если группа пустая, берем всю строку\n",
    "                                caption = line\n",
    "                            break\n",
    "                            \n",
    "                except Exception as e:\n",
    "                    print(f\"Ошибка при поиске подписи: {e}\")\n",
    "\n",
    "                metadata_list.append({\n",
    "                    \"image_path\": img_path,\n",
    "                    \"source_file\": base_name,\n",
    "                    \"page\": page_num + 1,\n",
    "                    \"chapter\": chapter,\n",
    "                    \"width\": width,\n",
    "                    \"height\": height,\n",
    "                    \"is_color\": is_color,\n",
    "                    \"class\": file_class,\n",
    "                    \"caption\": caption\n",
    "                })\n",
    "\n",
    "            except (ValueError, UnidentifiedImageError, fitz.fitz.BaseError) as e:\n",
    "                print(f\"Ошибка при обработке изображения {xref} на странице {page_num + 1}: {e}\")\n",
    "                continue\n",
    "\n",
    "    doc.close()\n",
    "    return metadata_list\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    pdf_folder = \"pdf_files\"\n",
    "    output_root = \"extracted_images_3\"\n",
    "    all_metadata = []\n",
    "\n",
    "    for pdf_file in os.listdir(pdf_folder):\n",
    "        if pdf_file.lower().endswith(\".pdf\"):\n",
    "            pdf_path = os.path.join(pdf_folder, pdf_file)\n",
    "            pdf_output_folder = os.path.join(output_root, os.path.splitext(pdf_file)[0])\n",
    "            try:\n",
    "                print(f\"Обработка файла: {pdf_file}...\")\n",
    "                metadata = extract_images_from_pdf(pdf_path, pdf_output_folder)\n",
    "                all_metadata.extend(metadata)\n",
    "                print(f\"Файл {pdf_file} успешно обработан. Извлечено изображений: {len(metadata)}\")\n",
    "            except fitz.fitz.FileNotFoundError:\n",
    "                print(f\"ОШИБКА: Файл не найден: {pdf_file}\")\n",
    "            except fitz.fitz.EmptyFileError:\n",
    "                print(f\"ОШИБКА: Пустой PDF файл: {pdf_file}\")\n",
    "            except fitz.fitz.PDFError as e:\n",
    "                print(f\"ОШИБКА: Поврежденный PDF файл {pdf_file}: {str(e)}\")\n",
    "            except PermissionError:\n",
    "                print(f\"ОШИБКА: Нет доступа к файлу: {pdf_file}\")\n",
    "            except Exception as e:\n",
    "                print(f\"КРИТИЧЕСКАЯ ОШИБКА при обработке файла {pdf_file}: {str(e)}\")\n",
    "                print(f\"Тип исключения: {type(e).__name__}\")\n",
    "                if hasattr(e, '__traceback__'):\n",
    "                    import traceback\n",
    "                    traceback.print_exc()\n",
    "    # Создаем DataFrame и сохраняем\n",
    "    df = pd.DataFrame(all_metadata)\n",
    "    df.to_csv(\"images_metadata.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674f310f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) Обучение классификатора - 6 классов \n",
    "\n",
    "def train_classifier(data_root, epochs=5, bs=32, lr=1e-3, device='cuda'):\n",
    "    tf = transforms.Compose([\n",
    "        transforms.Resize((224,224)), transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n",
    "    ])\n",
    "    ds = ImageFolder(os.path.join(data_root,'train'), transform=tf)\n",
    "    tr,va = random_split(ds,[int(0.8*len(ds)),len(ds)-int(0.8*len(ds))])\n",
    "    dl_tr = DataLoader(tr, bs, shuffle=True)\n",
    "    dl_va = DataLoader(va, bs)\n",
    "\n",
    "    m = models.resnet50(pretrained=True)\n",
    "    m.fc = nn.Linear(m.fc.in_features, len(ds.classes))\n",
    "    m = m.to(device)\n",
    "    opt = optim.Adam(m.parameters(), lr=lr)\n",
    "    crit = nn.CrossEntropyLoss()\n",
    "    for e in range(epochs):\n",
    "        m.train()\n",
    "        tot=0\n",
    "        for x,y in dl_tr:\n",
    "            x,y = x.to(device),y.to(device)\n",
    "            opt.zero_grad(); z=m(x); loss=crit(z,y); loss.backward(); opt.step()\n",
    "            tot+=loss.item()\n",
    "        m.eval()\n",
    "        cor=0; cnt=0\n",
    "        with torch.no_grad():\n",
    "            for x,y in dl_va:\n",
    "                x,y=x.to(device),y.to(device)\n",
    "                cor+= (m(x).argmax(1)==y).sum().item(); cnt+=y.size(0)\n",
    "        print(f\"Ep{e+1} L={tot/len(dl_tr):.3f} Acc={cor/cnt:.3f}\")\n",
    "    return m, ds.classes\n",
    "\n",
    "# обучение:\n",
    "# classifier,classes = train_classifier('/mnt/data/data', epochs=3)\n",
    "\n",
    "\n",
    "# 4) Строим эмбеддинги и поиск похожих\n",
    "\n",
    "def get_embeddings(paths, backbone, classifier=None, device='cuda'):\n",
    "    bb = torch.nn.Sequential(*list(backbone.children())[:-1]).to(device).eval()\n",
    "    tf = transforms.Compose([\n",
    "        transforms.Resize((224,224)), transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n",
    "    ])\n",
    "    embs=[]\n",
    "    preds=[]\n",
    "    for p in paths:\n",
    "        im = Image.open(p).convert('RGB')\n",
    "        x = tf(im).unsqueeze(0).to(device)\n",
    "        with torch.no_grad():\n",
    "            e = bb(x).squeeze().cpu().numpy(); embs.append(e)\n",
    "            if classifier:\n",
    "                preds.append(classes[classifier(x).argmax(1).item()])\n",
    "    return np.vstack(embs), preds\n",
    "\n",
    "class Searcher:\n",
    "    def __init__(self, embs, paths, df):\n",
    "        self.nn = NearestNeighbors(metric='cosine').fit(embs)\n",
    "        self.paths,self.df = paths,df\n",
    "    def query(self, qpath, k=5):\n",
    "        e,_ = get_embeddings([qpath], backbone, classifier)\n",
    "        ds,idxs = self.nn.kneighbors(e, k)\n",
    "        res=[]\n",
    "        for d,i in zip(ds[0],idxs[0]):\n",
    "            row=self.df.iloc[i]\n",
    "            res.append({'path':row.image_path,'file':row.source_file,'page':row.page,'dist':d})\n",
    "        return res\n",
    "\n",
    "# Пример поиска\n",
    "# backbone = models.resnet50(pretrained=True)\n",
    "# searcher = Searcher(embs, df.image_path.tolist(), df)\\# results = searcher.query('/mnt/data/query.png')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
